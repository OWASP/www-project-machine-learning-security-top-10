---
title: Related
layout: null
tab: true
order: 2
tags: related-tag
---

# Related

**Top 10 lists related to ML and AI:**

Top10 lists similar to famous OWASP Top10 for Web Applications list, but for AI:

- [MLSecOps Top10](https://ethical.institute/security.html)
- [OWASP Top10 for Large Language Models](https://owasp.org/www-project-top-10-for-large-language-model-applications/)

**Vulnerability databases:**

Catalogued vulnerabilities and risks that were present in real-world AI and ML
systems:

- [AI Vulnerability Database (AVID)](https://avidml.org/)
- [MITRE ATLAS](https://atlas.mitre.org/)
- [AI Risk Database](https://airisk.io/)

**AI/ML security guidelines:**

Various guidelines on ML and AI Security and Safety

- [OWASP AI Security and Privacy Guide](https://owasp.org/www-project-ai-security-and-privacy-guide/)
- [ETSI "Securing Artificial Intelligence](https://www.etsi.org/technologies/securing-artificial-intelligence)
- [Biden&Harris Administraton - Ensuring Safe, Secure and Trustworthy AI](https://www.whitehouse.gov/wp-content/uploads/2023/07/Ensuring-Safe-Secure-and-Trustworthy-AI.pdf)

**Playbooks**

Interactive playbooks useful in threat modelling and securing AI.

- [NIST AI Risk Management Framework Playbook](https://pages.nist.gov/AIRMF/)
- [Department of Energy AI Risk Management Playbook](https://www.energy.gov/ai/doe-ai-risk-management-playbook-airmp)

**Other**

All the other resources related to ML Security - threat modelling resources,
risk assessments framework, "Awesome Lists" etc.

- [Google on Red Teaming AI](https://services.google.com/fh/files/blogs/google_ai_red_team_digital_final.pdf)
- [Berryville ML Institute Resources for Threat Modelling ML]([https://berryvilleiml.com/interactive/)
- [Microsoft AI Risk assessment framework](https://raw.githubusercontent.com/Azure/AI-Security-Risk-Assessment/main/AI_Risk_Assessment_v4.1.4.pdf)
- [ETSI document on securing Artificial Intelligence](https://www.etsi.org/technologies/securing-artificial-intelligence)
- [Trusted AI Adversarial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox)
- [ENISA - Securing Machine Learning Algorithms](https://www.enisa.europa.eu/publications/securing-machine-learning-algorithms)
- [Awesome AI Security](https://github.com/DeepSpaceHarbor/Awesome-AI-Security)
- [Awesome ML Security](https://github.com/trailofbits/awesome-ml-security)
- [Awesome Attacks on ML Privacy](https://github.com/stratosphereips/awesome-ml-privacy-attacks)
