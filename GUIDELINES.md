# How various roles can use this document
## ML Engineer/Analyst
Document can be used in the following ways:
   - Understanding the vulnerabilities that may occur in ML models.
   - Implementing the prevention strategies to mitigate the risks associated with each vulnerability listed in the document.
   - Using the Example Attack Scenarios to create tests that verify models resiliency.
## Data Engineer
Document can be used in the following ways:
   - Implementing prevention strategies to ensure data integrity and security.
   - Using risk factors to assess the security of data pipelines and storage.
## MLOps
Document can be used in the following ways:
   - Understanding the vulnerabilities to ensure secure deployment of ML models.
   - Implementing prevention strategies in MLOps pipelines to mitigate risks.
   - Help in monitoring and maintaining the security of ML systems in operation.
## Developer
Document can be used in the following ways:
   - Understanding the vulnerabilities to write secure code for ML applications.
   - Implementing prevention strategies in the development process to reduce security risks.
## Pentester/Security Engineer:
Document can be used in the following ways:
   - Using the document to design and execute penetration tests on ML systems.
   - Using prevention strategies to recommend security enhancements.
- Using Risk Factors and Threat Agents to conduct a threat modeling of ML systems
## CISO:
Document can be used in the following ways:
   - Source for developing comprehensive security policies and strategies dedicated to securing ML systems.
   - Guiding the organization's security practices and policies for secure ML usage.
   - Using risk factors to assess the organization's overall security posture in relation to ML systems.

# Is this document what you need?

This work overlaps with other projects that are run by the OWASP foundation and also work that was done by other organizations. It may be not suitable for your needs, especially if:
- you are looking for Large Language Models security reference (then check OWASP Top10 for LLM [here](https://owasp.org/www-project-top-10-for-large-language-model-applications/)) 
- you are working with areas such as ethics of AI, sustainability of AI etc. 
- you are looking for risk assessment framework or complete threat model for AI/ML systems (then check i.e. [AI RMF by NIST] (https://airc.nist.gov/AI_RMF_Knowledge_Base/AI_RMF))
- you are looking for real life vulnerabilities in AI/ML systems (check our RELATED.md document for more details) 

Of course, this document may be helpful to you, but if you are looking for something to help you solve the task listed above, it is worth checking out these documents.



