# [\#89 Issue](https://github.com/OWASP/www-project-machine-learning-security-top-10/issues/89) `open`: [FEEDBACK]: Consider excessive agency
**Labels**: `issues/general`, `issues/triage`


#### <img src="https://avatars.githubusercontent.com/u/796794?v=4" width="50">[robvanderveer](https://github.com/robvanderveer) opened issue at [2023-08-19 14:11](https://github.com/OWASP/www-project-machine-learning-security-top-10/issues/89):

### Type

General Feedback

### What would you like to report?

The LLM top 10 mentions excessive agency, because it is important to limit privileges /autonomy / have oversight over LLM's. This is a general AI problem. 
One could argue whether this is a security risk, and I would argue that it is, because just as AI models are unpredictable, they may also have been manipulated. 
I believe the ML top 10 also needs Excessive agency.

### Code of Conduct

- [X] I agree to follow this project's Code of Conduct




-------------------------------------------------------------------------------



[Export of Github issue for [OWASP/www-project-machine-learning-security-top-10](https://github.com/OWASP/www-project-machine-learning-security-top-10).]
